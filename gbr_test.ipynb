{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.770945819723227 , k:  20\n"
     ]
    }
   ],
   "source": [
    "k=18\n",
    "for number in range(1):\n",
    "    k=round(k+2,2)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "\n",
    "    # Функции для очистки и подготовки данных\n",
    "    mean_year = np.round(train_data.loc[train_data['HouseYear'] <= 2020, 'HouseYear'].mean())\n",
    "    mean_healthcare = np.round(train_data[\"Healthcare_1\"].mean())\n",
    "    mean_square_for_max = train_data.loc[(train_data['Rooms'] <= train_data.loc[(train_data['Square'] > 300), 'Rooms'].mean()), 'Square'].mean()\n",
    "    mean_square_for_big_ls = train_data.loc[train_data['LifeSquare'] > 250, 'Square'].mean()\n",
    "    mean_life_squae_for_max = train_data.loc[train_data['Square'] >= mean_square_for_big_ls, 'LifeSquare'].mean()\n",
    "    \n",
    "    mean_square_Kitchen=train_data.KitchenSquare.mean()\n",
    "    \n",
    "    def clean_year(df, mean_year):\n",
    "        df.loc[df['HouseYear'] > 2020, 'HouseYear'] = mean_year\n",
    "\n",
    "    def clean_life_square(df, koef_S_LS):\n",
    "        df.loc[(df['LifeSquare'] < 10) | (df['LifeSquare'].isnull()), 'LifeSquare'] = df['Square']*0.85\n",
    "        df.loc[df['LifeSquare'] > 250, 'LifeSquare'] = mean_life_squae_for_max\n",
    "\n",
    "    def clean_square(df, mean_square_for_max):\n",
    "        df.loc[(df['Square'] > 300), 'Square'] = mean_square_for_max\n",
    "\n",
    "    def clean_healthcare_1(df, mean_healthcare):\n",
    "        df.loc[df['Healthcare_1'].isnull(), 'Healthcare_1'] = mean_healthcare\n",
    "\n",
    "    def clean_rooms(df):\n",
    "        df.loc[(df['Rooms'] < 1) & (df['LifeSquare'] < 30), 'Rooms'] = 1\n",
    "        df.loc[(df['Rooms'] < 1) & (df['LifeSquare'] > 30) & (df['LifeSquare'] < 45), 'Rooms'] = 2\n",
    "        df.loc[(df['Rooms'] < 1) & (df['LifeSquare'] > 45) & (df['LifeSquare'] < 60), 'Rooms'] = 3\n",
    "        df.loc[(df['Rooms'] < 1) & (df['LifeSquare'] > 60) & (df['LifeSquare'] < 75), 'Rooms'] = 4\n",
    "        df.loc[(df['Rooms'] < 1) & (df['LifeSquare'] > 70), 'Rooms'] = 6\n",
    "        df.loc[(df['Rooms'] > 10), 'Rooms'] = 2\n",
    "    \n",
    "    def KitchenSquare(df, mean_square_for_max):\n",
    "        df.loc[(df['KitchenSquare'] < 3) | (df['KitchenSquare'].isnull()), 'KitchenSquare'] = 6\n",
    "        df.loc[(df['KitchenSquare'] > 24)] = 6\n",
    "\n",
    "    def prepare_data(df, mean_year=mean_year, mean_healthcare=mean_healthcare, mean_square_for_max=mean_square_for_max, mean_life_squae_for_max=mean_life_squae_for_max):\n",
    "        clean_year(df, mean_year)\n",
    "        clean_life_square(df, mean_life_squae_for_max)\n",
    "        clean_healthcare_1(df, mean_healthcare)\n",
    "        clean_rooms(df)\n",
    "        clean_square(df, mean_square_for_max)\n",
    "        KitchenSquare(df, mean_square_for_max)\n",
    "        \n",
    "\n",
    "    prepare_data(train_data)\n",
    "    prepare_data(test_data)\n",
    "\n",
    "    X = pd.get_dummies(train_data)\n",
    "    X.drop(\"Price\", axis=1, inplace=True)\n",
    "    X.drop(\"Id\", axis=1, inplace=True)\n",
    "    y = train_data.Price\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.16, random_state=42)\n",
    "    # переобучение и оценка модели\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    final_model = GradientBoostingRegressor(n_estimators=200, max_depth=5, random_state=42\n",
    "                                           )\n",
    "    # min_samples_split=5, subsample=0.5 , min_samples_leaf=4 \n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_gbr = final_model.predict(X_valid)\n",
    "    y_pred_train_gbr = final_model.predict(X_train)\n",
    "\n",
    "    print('r2: ', r2_score(y_valid, y_pred_gbr),', k: ',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем цены для тестовых данных и выгружаем в файл\n",
    "X_test = pd.get_dummies(test_data)\n",
    "X_test.drop(\"Id\", axis=1, inplace=True)\n",
    "test_data[\"Price\"] = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# экспорт в файл\n",
    "test_data.loc[:, ['Id', 'Price']].to_csv('best_gbr_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0     3545\n",
       "8.0     1105\n",
       "5.0      986\n",
       "10.0     892\n",
       "9.0      706\n",
       "7.0      522\n",
       "12.0     211\n",
       "11.0     195\n",
       "13.0      59\n",
       "14.0      41\n",
       "4.0       34\n",
       "15.0      29\n",
       "3.0       20\n",
       "16.0      15\n",
       "20.0      11\n",
       "17.0      11\n",
       "19.0       9\n",
       "18.0       4\n",
       "22.0       3\n",
       "23.0       1\n",
       "21.0       1\n",
       "Name: KitchenSquare, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.KitchenSquare.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7621056876187297 - test_size=0.16 - n_estimators=200, max_depth=5, random_state=42 (0.75339)\n",
    "\n",
    "r2:  0.770945819723227 , k:  20 - KSM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=1000\n",
    "# for number in range(200):\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.16, random_state=42)\n",
    "#     # переобучение и оценка модели\n",
    "#     from sklearn.ensemble import GradientBoostingRegressor\n",
    "#     final_model = GradientBoostingRegressor(n_estimators=200, max_depth=5, random_state=42\n",
    "#                                            )\n",
    "#     # min_samples_split=5, subsample=0.5 , min_samples_leaf=4 \n",
    "\n",
    "#     final_model.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred_gbr = final_model.predict(X_valid)\n",
    "#     y_pred_train_gbr = final_model.predict(X_train)\n",
    "\n",
    "#     print('r2: ', r2_score(y_valid, y_pred),', n_estimators: ',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2, mean_absolute_error as mae, mean_squared_error as mse\n",
    "import seaborn as sns\n",
    "def evaluate_preds(true_values, pred_values):\n",
    "    print(\"R2:\\t\" + str(round(r2(true_values, pred_values), 9)) + \"\\n\" +\n",
    "          \"MAE:\\t\" + str(round(mae(true_values, pred_values), 9)) + \"\\n\" +\n",
    "          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 9)))\n",
    "    \n",
    "    plt.figure(figsize=(10,10)) \n",
    "    \n",
    "    sns.scatterplot(x=pred_values, y=true_values)\n",
    "    \n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('True vs Predicted values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_preds = final_model.predict(X_train)\n",
    "# evaluate_preds(y_train, y_train_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
